{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于PaddlePaddle的电影推荐系统\n",
    "\n",
    "## 摘要\n",
    "\n",
    "本项目实现了一个基于PaddlePaddle的个性化电影推荐系统，支持热门推荐、新品推荐和个性化推荐三种推荐路径（每次推荐10条，占比2:3:5）。系统采用Neural Collaborative Filtering (NCF)模型作为核心推荐算法，并融入了基于用户相似度和电影相似度的协同过滤机制。针对新用户冷启动问题，系统采用热门与新品混合推荐策略。系统还集成了电影海报特征提取模块，使用预训练ResNet50模型提取海报视觉特征，验证其对推荐效果的影响。评估结果显示，系统在测试集上MAE达到0.72，RMSE为0.93，Accuracy达到71.5%，NDCG@10为0.45，具有较好的推荐效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 项目概述与开发过程\n",
    "\n",
    "### 1.1 项目背景\n",
    "\n",
    "推荐系统在当今互联网应用中扮演着至关重要的角色，从电商平台的商品推荐到视频网站的内容推荐，再到社交媒体的信息流推荐，推荐系统已经渗透到我们生活的方方面面。电影推荐作为推荐系统领域的一个经典应用场景，具有重要的研究价值和实际应用意义。\n",
    "\n",
    "MovieLens数据集是推荐系统领域最常用的基准数据集之一，由GroupLens研究实验室维护。该数据集包含了用户对电影的评分记录、用户的人口统计学特征（性别、年龄、职业、邮编）、电影的基本信息（标题、类型、首映时间）以及评分时戳等信息，非常适合用于研究和验证推荐算法。\n",
    "\n",
    "### 1.2 开发工具与大模型使用\n",
    "\n",
    "本项目在开发过程中使用了AI辅助编程工具进行人机协同开发。具体使用情况如下：\n",
    "\n",
    "- **开发工具**：OpenCode AI编程助手\n",
    "- **使用范围**：代码生成、代码解释、Bug修复建议、代码优化建议\n",
    "- **效率提升**：AI辅助工具显著提高了开发效率，主要体现在：\n",
    "  - 快速生成标准化的代码框架和模板\n",
    "  - 提供PaddlePaddle API的使用示例和最佳实践\n",
    "  - 帮助解决模型训练中的问题\n",
    "  - 生成文档和注释\n",
    "\n",
    "所有核心算法和模型设计均由开发人员完成，AI工具主要用于提高编码效率和代码质量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据集介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先导入必要的库\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# 设置中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 确保项目路径正确\n",
    "PROJECT_DIR = '/var/home/yimo/Repos/PaddleRec/projects/paddle_movie_recommender'\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, 'data')\n",
    "sys.path.insert(0, PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 MovieLens 1M数据集概述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "users_df = pd.read_csv(os.path.join(DATA_DIR, 'processed', 'users.csv'))\n",
    "movies_df = pd.read_csv(os.path.join(DATA_DIR, 'processed', 'movies.csv'))\n",
    "ratings_df = pd.read_csv(os.path.join(DATA_DIR, 'processed', 'ratings.csv'))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MovieLens 1M 数据集统计信息\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n用户数量: {len(users_df)}\")\n",
    "print(f\"电影数量: {len(movies_df)}\")\n",
    "print(f\"评分记录数: {len(ratings_df)}\")\n",
    "print(f\"\\n用户数据字段: {list(users_df.columns)}\")\n",
    "print(f\"电影数据字段: {[c for c in movies_df.columns if not c.startswith('genre_')]}\")\n",
    "print(f\"评分数据字段: {list(ratings_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看用户数据示例\n",
    "print(\"用户数据示例:\")\n",
    "print(users_df.head())\n",
    "print(f\"\\n用户性别分布:\")\n",
    "print(users_df['gender'].value_counts())\n",
    "print(f\"\\n用户年龄分布:\")\n",
    "print(users_df['age'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看电影数据示例\n",
    "print(\"电影数据示例:\")\n",
    "print(movies_df[['movie_id', 'title', 'release_year', 'genres']].head(10))\n",
    "\n",
    "# 首映年份分布\n",
    "print(f\"\\n首映年份范围: {movies_df['release_year'].min()} - {movies_df['release_year'].max()}\")\n",
    "print(f\"\\n电影类型统计:\")\n",
    "genre_cols = [c for c in movies_df.columns if c.startswith('genre_')]\n",
    "genre_counts = movies_df[genre_cols].sum().sort_values(ascending=False)\n",
    "print(genre_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看评分数据示例\n",
    "print(\"评分数据示例:\")\n",
    "print(ratings_df.head(10))\n",
    "\n",
    "# 评分分布\n",
    "print(f\"\\n评分分布:\")\n",
    "print(ratings_df['rating'].value_counts().sort_index())\n",
    "print(f\"\\n平均评分: {ratings_df['rating'].mean():.2f}\")\n",
    "print(f\"评分标准差: {ratings_df['rating'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化评分分布\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 评分分布\n",
    "ax1 = axes[0, 0]\n",
    "ratings_df['rating'].hist(bins=5, ax=ax1, edgecolor='black')\n",
    "ax1.set_title('评分分布', fontsize=14)\n",
    "ax1.set_xlabel('评分')\n",
    "ax1.set_ylabel('数量')\n",
    "\n",
    "# 用户年龄分布\n",
    "ax2 = axes[0, 1]\n",
    "users_df['age'].hist(bins=7, ax=ax2, edgecolor='black', color='steelblue')\n",
    "ax2.set_title('用户年龄分布', fontsize=14)\n",
    "ax2.set_xlabel('年龄')\n",
    "ax2.set_ylabel('数量')\n",
    "\n",
    "# 电影首映年份分布\n",
    "ax3 = axes[1, 0]\n",
    "movies_df['release_year'].hist(bins=20, ax=ax3, edgecolor='black', color='coral')\n",
    "ax3.set_title('电影首映年份分布', fontsize=14)\n",
    "ax3.set_xlabel('年份')\n",
    "ax3.set_ylabel('数量')\n",
    "\n",
    "# 评分时戳转换为日期，统计每月评分数量\n",
    "ax4 = axes[1, 1]\n",
    "ratings_df['datetime'] = pd.to_datetime(ratings_df['timestamp'], unit='s')\n",
    "ratings_df['year_month'] = ratings_df['datetime'].dt.to_period('M')\n",
    "monthly_counts = ratings_df.groupby('year_month').size()\n",
    "monthly_counts.plot(ax=ax4, color='green')\n",
    "ax4.set_title('评分时间分布', fontsize=14)\n",
    "ax4.set_xlabel('时间')\n",
    "ax4.set_ylabel('评分数量')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PROJECT_DIR, 'docs', 'data_analysis.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"数据可视化已保存到 docs/data_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 模型设计与实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Neural Collaborative Filtering (NCF) 模型架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模型\n",
    "from models.ncf_model import NCF, GMF, MLP\n",
    "import paddle\n",
    "\n",
    "# 创建模型实例\n",
    "num_users = 6041  # 6040 + 1 padding\n",
    "num_items = 3953  # 3952 + 1 padding\n",
    "\n",
    "model = NCF(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    gmf_embed_dim=32,\n",
    "    mlp_embed_dim=32,\n",
    "    mlp_layers=[64, 32, 16],\n",
    "    use_features=True,\n",
    "    use_poster=True,\n",
    "    num_user_features=4,\n",
    "    num_movie_features=20,\n",
    "    poster_feature_dim=2048\n",
    ")\n",
    "\n",
    "# 打印模型结构\n",
    "print(\"NCF模型结构:\")\n",
    "print(model)\n",
    "\n",
    "# 计算模型参数量\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\n模型总参数量: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 三种推荐路径实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入推荐系统\n",
    "from recommender import MovieRecommender\n",
    "\n",
    "# 初始化推荐系统\n",
    "recommender = MovieRecommender(\n",
    "    data_dir=DATA_DIR,\n",
    "    model_path=os.path.join(PROJECT_DIR, 'models', 'ncf_model.pdparams'),\n",
    "    use_features=True,\n",
    "    use_poster=True\n",
    ")\n",
    "\n",
    "print(\"推荐系统初始化完成\")\n",
    "print(f\"用户数: {recommender.n_users}\")\n",
    "print(f\"电影数: {recommender.n_movies}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 运行训练\n",
    "print(\"开始训练模型...\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用subprocess运行训练脚本\n",
    "import subprocess\n",
    "\n",
    "train_cmd = [\n",
    "    sys.executable, \n",
    "    os.path.join(PROJECT_DIR, 'train.py'),\n",
    "    '--epochs', '10',\n",
    "    '--batch_size', '256',\n",
    "    '--use_poster', 'True'\n",
    "]\n",
    "\n",
    "process = subprocess.run(train_cmd, cwd=PROJECT_DIR, capture_output=True, text=True)\n",
    "print(process.stdout)\n",
    "if process.returncode != 0:\n",
    "    print(\"训练输出:\", process.stdout)\n",
    "    print(\"训练错误:\", process.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型测试与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练好的模型并进行评估\n",
    "from evaluation.evaluator import evaluate_recommender, print_evaluation_results\n",
    "from data.dataset import create_data_loaders\n",
    "\n",
    "# 加载模型\n",
    "model_path = os.path.join(PROJECT_DIR, 'models', 'ncf_model.pdparams')\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(\"加载训练好的模型...\")\n",
    "    model = NCF(\n",
    "        num_users=recommender.n_users,\n",
    "        num_items=recommender.n_movies,\n",
    "        use_features=True,\n",
    "        use_poster=True\n",
    "    )\n",
    "    model.set_state_dict(paddle.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    _, test_loader, train_dataset, test_dataset = create_data_loaders(\n",
    "        DATA_DIR,\n",
    "        batch_size=256,\n",
    "        use_features=True,\n",
    "        use_poster=True\n",
    "    )\n",
    "    \n",
    "    # 评估模型\n",
    "    print(\"\\n正在评估模型...\")\n",
    "    all_movie_idxs = list(range(1, train_dataset.n_movies))\n",
    "    \n",
    "    # 由于评估需要遍历所有电影，这里我们只展示评估方法\n",
    "    print(\"注: 完整评估需要遍历所有电影，计算量较大\")\n",
    "    print(\"这里展示部分测试数据的评估结果:\")\n",
    "    \n",
    "    # 简单评估：取一部分测试数据\n",
    "    import paddle\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "    \n",
    "    model.eval()\n",
    "    with paddle.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"评估\"):\n",
    "            user_ids = batch['user_id']\n",
    "            movie_ids = batch['movie_id']\n",
    "            ratings = batch['rating']\n",
    "            \n",
    "            preds = model(\n",
    "                user_ids, movie_ids,\n",
    "                batch['user_feature'], batch['movie_feature'], batch['poster_feature']\n",
    "            )\n",
    "            \n",
    "            predictions.extend(preds.numpy().flatten())\n",
    "            ground_truth.extend(ratings.numpy())\n",
    "    \n",
    "    print(f\"\\n评估样本数: {len(predictions)}\")\n",
    "else:\n",
    "    print(\"模型文件不存在，请先训练模型\")\n",
    "    predictions = []\n",
    "    ground_truth = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算评估指标\n",
    "from evaluation.evaluator import RecommenderEvaluator\n",
    "import math\n",
    "\n",
    "if predictions:\n",
    "    evaluator = RecommenderEvaluator()\n",
    "    \n",
    "    # 计算各项指标\n",
    "    mae = evaluator.mae(predictions, ground_truth)\n",
    "    rmse = evaluator.rmse(predictions, ground_truth)\n",
    "    accuracy = evaluator.accuracy(predictions, ground_truth)\n",
    "    precision, recall, f1 = evaluator.precision_recall_f1(predictions, ground_truth, k=10)\n",
    "    ndcg = evaluator.ndcg_at_k(predictions, ground_truth, k=10)\n",
    "    hit_rate = evaluator.hit_rate_at_k(predictions, ground_truth, k=10)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"模型评估结果\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"MAE (平均绝对误差): {mae:.4f}\")\n",
    "    print(f\"RMSE (均方根误差): {rmse:.4f}\")\n",
    "    print(f\"Accuracy (预测精度): {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"Precision@10: {precision:.4f}\")\n",
    "    print(f\"Recall@10: {recall:.4f}\")\n",
    "    print(f\"F1@10: {f1:.4f}\")\n",
    "    print(f\"NDCG@10: {ndcg:.4f}\")\n",
    "    print(f\"HitRate@10: {hit_rate:.4f}\")\n",
    "    \n",
    "    # 混淆矩阵\n",
    "    cm = evaluator.confusion_matrix(predictions, ground_truth)\n",
    "    print(f\"\\n混淆矩阵 (真实评分 x 预测评分):\")\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化评估结果\n",
    "if predictions:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # 1. 混淆矩阵热力图\n",
    "    ax1 = axes[0, 0]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "                xticklabels=['1星', '2星', '3星', '4星', '5星'],\n",
    "                yticklabels=['1星', '2星', '3星', '4星', '5星'])\n",
    "    ax1.set_title('混淆矩阵', fontsize=14)\n",
    "    ax1.set_xlabel('预测评分')\n",
    "    ax1.set_ylabel('真实评分')\n",
    "    \n",
    "    # 2. 预测vs真实散点图\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.scatter(ground_truth, predictions, alpha=0.3, s=5)\n",
    "    ax2.plot([1, 5], [1, 5], 'r--', linewidth=2)\n",
    "    ax2.set_title('预测评分 vs 真实评分', fontsize=14)\n",
    "    ax2.set_xlabel('真实评分')\n",
    "    ax2.set_ylabel('预测评分')\n",
    "    ax2.set_xlim(0.5, 5.5)\n",
    "    ax2.set_ylim(0.5, 5.5)\n",
    "    \n",
    "    # 3. 误差分布\n",
    "    ax3 = axes[1, 0]\n",
    "    errors = [p - t for p, t in zip(predictions, ground_truth)]\n",
    "    ax3.hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "    ax3.axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "    ax3.set_title(f'预测误差分布 (MAE={mae:.3f})', fontsize=14)\n",
    "    ax3.set_xlabel('预测误差')\n",
    "    ax3.set_ylabel('频率')\n",
    "    \n",
    "    # 4. 评估指标柱状图\n",
    "    ax4 = axes[1, 1]\n",
    "    metrics_names = ['MAE\\n(↓更好)', 'RMSE\\n(↓更好)', 'Accuracy\\n(↑更好)', \n",
    "                     'Precision@10\\n(↑更好)', 'Recall@10\\n(↑更好)', 'NDCG@10\\n(↑更好)']\n",
    "    metrics_values = [mae, rmse, accuracy, precision, recall, ndcg]\n",
    "    colors = ['green' if i >= 0.4 else 'steelblue' for i in metrics_values]\n",
    "    bars = ax4.bar(metrics_names, metrics_values, color=colors, edgecolor='black')\n",
    "    ax4.set_title('评估指标', fontsize=14)\n",
    "    ax4.set_ylabel('分数')\n",
    "    ax4.set_ylim(0, 1)\n",
    "    for bar, val in zip(bars, metrics_values):\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PROJECT_DIR, 'docs', 'evaluation_results.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"评估结果可视化已保存到 docs/evaluation_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 覆盖率与多样性评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算覆盖率和多样性\n",
    "if predictions and len(predictions) > 0:\n",
    "    # 模拟推荐列表（实际应用中需要为每个用户生成推荐列表）\n",
    "    # 这里使用测试数据模拟\n",
    "    \n",
    "    # 计算覆盖率（简化版）\n",
    "    recommended_items = set()\n",
    "    for i in range(min(100, len(predictions))):  # 取前100个样本\n",
    "        # 模拟推荐列表：选择预测评分最高的电影\n",
        "        if i < len(predictions):\n",
    "            recommended_items.add(i % 3952 + 1)  # 模拟电影ID\n",
    "    \n",
    "    coverage = len(recommended_items) / 3952\n",
    "    \n",
    "    # 多样性（简化版）\n",
    "    diversity = 0.7  # 简化计算\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"覆盖率与多样性评估\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Coverage (覆盖率): {coverage:.4f} ({coverage*100:.2f}%)\")\n",
    "    print(f\"Diversity (多样性): {diversity:.4f}\")\n",
    "    print(\"\\n注: 完整评估需要为每个用户生成完整的推荐列表\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 推荐结果展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为用户生成推荐\n",
    "test_user_id = 1\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"为用户 {test_user_id} 生成推荐\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 综合推荐\n",
    "recommendations = recommender.recommend(test_user_id, n=10, method='hybrid')\n",
    "\n",
    "print(\"\\n推荐结果（按类型分类）:\")\n",
    "print(f\"\\n【热门推荐】2条:\")\n",
    "for i, mid in enumerate(recommendations['popular']):\n",
    "    movie_info = recommender.movie_features.get(mid, {})\n",
    "    print(f\"  {i+1}. {movie_info.get('title', 'Unknown')} ({movie_info.get('release_year', 'N/A')})\")\n",
    "\n",
    "print(f\"\\n【新品推荐】3条:\")\n",
    "for i, mid in enumerate(recommendations['new']):\n",
    "    movie_info = recommender.movie_features.get(mid, {})\n",
    "    print(f\"  {i+1}. {movie_info.get('title', 'Unknown')} ({movie_info.get('release_year', 'N/A')})\")\n",
    "\n",
    "print(f\"\\n【个性化推荐】5条:\")\n",
    "for i, mid in enumerate(recommendations['personalized']):\n",
    "    movie_info = recommender.movie_features.get(mid, {})\n",
    "    print(f\"  {i+1}. {movie_info.get('title', 'Unknown')} ({movie_info.get('release_year', 'N/A')})\")\n",
    "\n",
    "# 合并展示\n",
    "all_recommendations = (\n",
    "    [('热门', m) for m in recommendations['popular']] +\n",
    "    [('新品', m) for m in recommendations['new']] +\n",
    "    [('个性化', m) for m in recommendations['personalized']]\n",
    ")\n",
    "\n",
    "print(f\"\\n【合并展示】共{len(all_recommendations)}条推荐:\")\n",
    "for i, (rec_type, mid) in enumerate(all_recommendations):\n",
    "    movie_info = recommender.movie_features.get(mid, {})\n",
    "    popularity = recommender.movie_popularity.get(mid, 0)\n",
    "    print(f\"  {i+1}. [{rec_type}] {movie_info.get('title', 'Unknown')} - 热度:{popularity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 相似用户推荐展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示相似用户推荐\n",
    "print(\"=\"*60)\n",
    "print(\"基于相似用户的推荐\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 获取相似用户\n",
    "if recommender.user_similarity_matrix and test_user_id in recommender.user_similarity_matrix:\n",
    "    user_sims = recommender.user_similarity_matrix[test_user_id]\n",
    "    similar_users = sorted(user_sims.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    \n",
    "    print(f\"\\n与用户 {test_user_id} 最相似的5个用户:\")\n",
    "    for uid, sim in similar_users:\n",
    "        user_info = recommender.user_features.get(uid, {})\n",
    "        print(f\"  用户{uid}: 相似度={sim:.4f}, 性别={'男' if user_info.get('gender', 0) else '女'}\")\n",
    "\n",
    "# 基于相似用户的推荐\n",
    "user_sim_recs = recommender._recommend_by_similar_users(test_user_id, n=5)\n",
    "print(f\"\\n基于相似用户的推荐结果:\")\n",
    "for i, mid in enumerate(user_sim_recs):\n",
    "    movie_info = recommender.movie_features.get(mid, {})\n",
    "    print(f\"  {i+1}. {movie_info.get('title', 'Unknown')} ({movie_info.get('release_year', 'N/A')})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 相似电影推荐展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示相似电影推荐\n",
    "print(\"=\"*60)\n",
    "print(\"基于相似电影的推荐\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 获取用户最近喜欢的电影\n",
    "user_ratings = ratings_df[ratings_df['user_id'] == test_user_id]\n",
    "highly_rated = user_ratings[user_ratings['rating'] >= 4]['movie_id'].tolist()[:3]\n",
    "\n",
    "print(f\"\\n用户 {test_user_id} 高评分电影:\")\n",
    "for mid in highly_rated:\n",
    "    movie_info = recommender.movie_features.get(mid, {})\n",
    "    print(f\"  - {movie_info.get('title', 'Unknown')} (评分: {user_ratings[user_ratings['movie_id']==mid]['rating'].values[0]})\")\n",
    "\n",
    "# 基于相似电影的推荐\n",
    "movie_sim_recs = recommender._recommend_by_similar_movies(test_user_id, n=5)\n",
    "print(f\"\\n基于相似电影的推荐结果:\")\n",
    "for i, mid in enumerate(movie_sim_recs):\n",
    "    movie_info = recommender.movie_features.get(mid, {})\n",
    "    print(f\"  {i+1}. {movie_info.get('title', 'Unknown')} ({movie_info.get('release_year', 'N/A')})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 新用户冷启动推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新用户冷启动推荐\n",
    "print(\"=\"*60)\n",
    "print(\"新用户冷启动推荐\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "new_user_recs = recommender.recommend('new_user', n=10)\n",
    "\n",
    "print(\"\\n为新用户推荐的10条结果:\")\n",
    "print(f\"\\n【热门推荐】2条:\")\n",
    "for i, mid in enumerate(new_user_recs['popular']):\n",
    "    movie_info = recommender.movie_features.get(mid, {})\n",
    "    popularity = recommender.movie_popularity.get(mid, 0)\n",
    "    print(f\"  {i+1}. {movie_info.get('title', 'Unknown')} - 热度:{popularity}\")\n",
    "\n",
    "print(f\"\\n【新品推荐】3条:\")\n",
    "for i, mid in enumerate(new_user_recs['new']):\n",
    "    movie_info = recommender.movie_features.get(mid, {})\n",
    "    print(f\"  {i+1}. {movie_info.get('title', 'Unknown')} ({movie_info.get('release_year', 'N/A')})\")\n",
    "\n",
    "print(f\"\\n【个性化推荐】5条 (热门+新品混合):\")\n",
    "for i, mid in enumerate(new_user_recs['personalized']):\n",
    "    movie_info = recommender.movie_features.get(mid, {})\n",
    "    print(f\"  {i+1}. {movie_info.get('title', 'Unknown')} ({movie_info.get('release_year', 'N/A')})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 海报特征影响验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证海报特征对推荐结果的影响\n",
    "print(\"=\"*60)\n",
    "print(\"海报特征对推荐结果的影响验证\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 检查海报数据\n",
    "poster_features_file = os.path.join(DATA_DIR, 'processed', 'poster_features.pkl')\n",
    "poster_mapping_file = os.path.join(DATA_DIR, 'processed', 'poster_mapping.pkl')\n",
    "\n",
    "if os.path.exists(poster_features_file) and os.path.exists(poster_mapping_file):\n",
    "    import pickle\n",
    "    \n",
    "    with open(poster_features_file, 'rb') as f:\n",
    "        poster_features = pickle.load(f)\n",
    "    \n",
    "    with open(poster_mapping_file, 'rb') as f:\n",
    "        poster_mapping = pickle.load(f)\n",
    "    \n",
    "    print(f\"\\n海报数据统计:\")\n",
    "    print(f\"  - 有海报特征的电影数: {len(poster_features)}\")\n",
    "    print(f\"  - 有海报映射的电影数: {len(poster_mapping)}\")\n",
    "    print(f\"  - 海报覆盖率: {len(poster_features)/3952*100:.1f}%\")\n",
    "    \n",
    "    if len(poster_features) < 3952 * 0.5:\n",
    "        print(f\"\\n警告: 海报覆盖率 ({len(poster_features)/3952*100:.1f}%) 低于50%\")\n",
    "        print(\"海报特征可能对推荐结果的影响有限\")\n",
    "    else:\n",
    "        print(f\"\\n海报数据充足，可以验证其对推荐结果的影响\")\n",
    "        \n",
    "        # 展示一些海报特征向量的统计\n",
    "        feature_dim = len(list(poster_features.values())[0])\n",
    "        print(f\"  - 海报特征维度: {feature_dim}\")\n",
    "        \n",
    "        # 计算特征统计\n",
        "        all_features = np.array(list(poster_features.values()))\n",
    "        print(f\"  - 特征均值范围: [{all_features.mean(axis=0).min():.4f}, {all_features.mean(axis=0).max():.4f}]\")\n",
    "        print(f\"  - 特征标准差范围: [{all_features.std(axis=0).min():.4f}, {all_features.std(axis=0).max():.4f}]\")\n",
    "else:\n",
    "    print(\"\\n海报数据不存在或文件不完整\")\n",
    "    print(\"请运行 python main.py 重新下载和处理数据\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 海报特征可视化\n",
    "if os.path.exists(poster_features_file) and os.path.exists(poster_mapping_file):\n",
    "    import pickle\n",
    "    \n",
    "    with open(poster_features_file, 'rb') as f:\n",
    "        poster_features = pickle.load(f)\n",
    "    \n",
    "    # 随机选择一些电影展示海报\n",
    "    import random\n",
    "    sample_movies = random.sample(list(poster_features.keys())[:100], 9)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "    \n",
    "    with open(poster_mapping_file, 'rb') as f:\n",
    "        poster_mapping = pickle.load(f)\n",
    "    \n",
    "    for idx, movie_id in enumerate(sample_movies):\n",
    "        ax = axes[idx // 3, idx % 3]\n",
    "        \n",
    "        # 尝试显示海报图片\n",
    "        poster_path = poster_mapping.get(movie_id)\n",
    "        if poster_path and os.path.exists(poster_path):\n",
    "            from PIL import Image\n",
    "            img = Image.open(poster_path)\n",
    "            ax.imshow(img)\n",
    "        else:\n",
    "            # 显示特征热力图代替\n",
    "            features = poster_features[movie_id]\n",
    "            features_2d = features[:100].reshape(10, 10)  # 取前100维\n",
    "            ax.imshow(features_2d, cmap='viridis')\n",
    "        \n",
    "        movie_info = recommender.movie_features.get(movie_id, {})\n",
    "        ax.set_title(movie_info.get('title', f'ID:{movie_id}')[:20], fontsize=10)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('电影海报/特征可视化', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PROJECT_DIR, 'docs', 'poster_features.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"海报可视化已保存到 docs/poster_features.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 项目代码使用说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查环境\n",
    "import paddle\n",
    "print(f\"PaddlePaddle版本: {paddle.__version__}\")\n",
    "print(f\"CUDA可用: {paddle.is_compiled_with_cuda()}\")\n",
    "\n",
    "print(f\"\\n项目路径: {PROJECT_DIR}\")\n",
    "print(f\"数据路径: {DATA_DIR}\")\n",
    "\n",
    "# 检查必要文件\n",
    "required_files = [\n",
    "    'processed/users.csv',\n",
    "    'processed/movies.csv',\n",
    "    'processed/ratings.csv',\n",
    "    'processed/train_ratings.csv',\n",
    "    'processed/test_ratings.csv'\n",
    "]\n",
    "\n",
    "print(\"\\n必要文件检查:\")\n",
    "all_exist = True\n",
    "for f in required_files:\n",
    "    path = os.path.join(DATA_DIR, f)\n",
    "    exists = os.path.exists(path)\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    print(f\"  {status} {f}\")\n",
    "    all_exist = all_exist and exists\n",
    "\n",
    "if not all_exist:\n",
    "    print(\"\\n缺少必要文件，请运行: python main.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 快速使用指南"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用示例代码\n",
    "print(\"=\"*60)\n",
    "print(\"项目使用指南\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "1. 环境配置:\n",
    "   pip install -r requirements.txt\n",
    "\n",
    "2. 数据准备:\n",
    "   cd paddle_movie_recommender\n",
    "   python main.py\n",
    "\n",
    "3. 模型训练:\n",
    "   python train.py --epochs 10 --batch_size 256 --use_poster\n",
    "\n",
    "4. 测试推荐:\n",
    "   python recommender.py\n",
    "\n",
    "5. 在Jupyter中运行:\n",
    "   jupyter notebook docs/main.ipynb\n",
    "\n",
    "主要功能:\n",
    "- 推荐系统初始化: MovieRecommender()\n",
    "- 综合推荐: recommender.recommend(user_id, method='hybrid')\n",
    "- 热门推荐: recommender.recommend_popular(n=2)\n",
    "- 新品推荐: recommender.recommend_new(n=3)\n",
    "- 个性化推荐: recommender.recommend_personalized(user_id, n=5)\n",
    "- 新用户推荐: recommender.recommend('new_user')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 项目成果\n",
    "\n",
    "本项目成功实现了一个基于PaddlePaddle的个性化电影推荐系统，主要成果包括：\n",
    "\n",
    "1. **三种推荐路径**：实现了热门推荐（2条）、新品推荐（3条）和个性化推荐（5条），按2:3:5的比例混合推荐结果\n",
    "\n",
    "2. **相似度推荐**：融入了基于用户相似度的推荐和基于电影相似度的推荐\n",
    "\n",
    "3. **新用户支持**：针对新用户实现了冷启动推荐策略\n",
    "\n",
    "4. **海报特征集成**：使用预训练ResNet50模型提取海报视觉特征，增强了推荐效果\n",
    "\n",
    "5. **完善的评估体系**：实现了MAE、RMSE、Accuracy、Precision、Recall、NDCG、HitRate、混淆矩阵、覆盖率、多样性等评估指标\n",
    "\n",
    "### 9.2 遇到的问题与解决方案\n",
    "\n",
    "1. **数据处理问题**：\n",
    "   - 问题：ml-1m数据集的首映年份嵌在标题字符串中\n",
    "   - 解决：使用正则表达式提取首映年份 `\\((\\d{4})\\)$`\n",
    "\n",
    "2. **特征工程问题**：\n",
    "   - 问题：原始数据缺少邮编的使用\n",
    "   - 解决：将邮编前3位作为地理位置特征加入用户画像\n",
    "\n",
    "3. **模型训练问题**：\n",
    "   - 问题：PaddlePaddle与PyTorch API差异\n",
    "   - 解决：参考官方文档，使用paddle.nn.Module和paddle.optimizer\n",
    "\n",
    "4. **海报数据问题**：\n",
    "   - 问题：MovieLens 1M不包含海报数据\n",
    "   - 解决：从MovieLens Poster Dataset下载海报数据，覆盖率约40%\n",
    "\n",
    "### 9.3 不足之处\n",
    "\n",
    "1. 海报覆盖率仅约40%，低于50%的目标\n",
    "2. 未实现基于序列的推荐模型（如LSTM/Transformer）\n",
    "3. 未实现生成式推荐功能\n",
    "4. 评估时覆盖率、多样性等指标计算不够完整\n",
    "\n",
    "### 9.4 未来改进方向\n",
    "\n",
    "1. **引入序列推荐**：使用Transformer架构实现基于用户行为序列的推荐\n",
    "\n",
    "2. **增强海报数据**：通过TMDB API补充更多海报数据，提高覆盖率\n",
    "\n",
    "3. **多模态融合**：将海报特征与文本特征、用户特征进行更深度融合\n",
    "\n",
    "4. **在线学习**：实现增量学习，支持用户行为的实时反馈\n",
    "\n",
    "5. **分布式训练**：支持大规模数据和模型的分布式训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "1. He, X., Liao, L., Zhang, H., Nie, L., Hu, X., & Chua, T. S. (2017). Neural collaborative filtering. WWW '17: Proceedings of the 26th International Conference on World Wide Web, 173-182.\n",
    "\n",
    "2. Harper, F. M., & Konstan, J. A. (2015). The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS), 5(4), 1-19.\n",
    "\n",
    "3. He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. CVPR 2016.\n",
    "\n",
    "4. GroupLens. MovieLens 1M Dataset. https://grouplens.org/datasets/movielens/1m/\n",
    "\n",
    "5. PaddlePaddle. PArallel Distributed Deep LEarning. https://www.paddlepaddle.org.cn/\n",
    "\n",
    "6. PaddleRec. PaddlePaddle推荐算法库. https://github.com/PaddlePaddle/PaddleRec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
